{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c059340",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.006862,
     "end_time": "2023-10-16T01:24:45.600458",
     "exception": false,
     "start_time": "2023-10-16T01:24:45.593596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**GOALS挑战赛任务一基线**  \n",
    "\n",
    "赛题链接：MICCAI2022 Challenge: GOALS (Task 1)\n",
    "https://aistudio.baidu.com/aistudio/competition/detail/230/0/introduction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5103ec",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.004254,
     "end_time": "2023-10-16T01:24:45.609761",
     "exception": false,
     "start_time": "2023-10-16T01:24:45.605507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**比赛简介**  \n",
    "\n",
    "GOALS挑战赛是由百度在MICCAI 2022上举办的国际眼科赛事。MICCAI是由国际医学图像计算和计算机辅助干预协会 (Medical Image Computing and Computer Assisted Intervention Society) 举办的跨医学影像计算和计算机辅助介入两个领域的综合性学术会议，是该领域的顶级会议。与此同时，百度将在MICCAI 2022上组织第九届眼科医学影像分析研讨会Ophthalmic Medical Image Analysis (OMIA9)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c148e1b",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.0041,
     "end_time": "2023-10-16T01:24:45.618207",
     "exception": false,
     "start_time": "2023-10-16T01:24:45.614107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**基线任务说明**    \n",
    "\n",
    "本基线对应GOALS比赛任务1，目的是在环扫OCT图像中分割视神经纤维层、神经节细胞丛层和脉络膜层区域。\n",
    "本基线使用了U型网络结构，并在编码和解码阶段加入了残差模块，模型结构如下图所示。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/dc2e371fe6544123a77700563b85598660d3f09f006b4d6d8696d268d5b045c0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4884a",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.004152,
     "end_time": "2023-10-16T01:24:45.626908",
     "exception": false,
     "start_time": "2023-10-16T01:24:45.622756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**数据集说明**  \n",
    "\n",
    "本基线使用的数据集为GOALS比赛释放的环扫OCT图像。代码中提供的读入数据仅供基线正常运行，并非完整比赛数据集。\n",
    "各位同学可通过报名GOALS比赛获得相应数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "480352bc",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:45.644824Z",
     "iopub.status.busy": "2023-10-16T01:24:45.643915Z",
     "iopub.status.idle": "2023-10-16T01:24:48.579621Z",
     "shell.execute_reply": "2023-10-16T01:24:48.580090Z"
    },
    "papermill": {
     "duration": 2.948843,
     "end_time": "2023-10-16T01:24:48.580261",
     "exception": false,
     "start_time": "2023-10-16T01:24:45.631418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.io import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3510a50",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:48.597020Z",
     "iopub.status.busy": "2023-10-16T01:24:48.596507Z",
     "iopub.status.idle": "2023-10-16T01:24:48.599013Z",
     "shell.execute_reply": "2023-10-16T01:24:48.598551Z"
    },
    "papermill": {
     "duration": 0.013833,
     "end_time": "2023-10-16T01:24:48.599124",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.585291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 设置参数\n",
    "images_file = 'work/Train/Image'  # 训练图像路径\n",
    "gt_file = 'work/Train/Layer_Masks'\n",
    "image_size = 256 # 输入图像统一尺寸\n",
    "val_ratio = 0.2  # 训练/验证图像划分比例\n",
    "BATCH_SIZE = 8 # 批大小\n",
    "iters = 2 # 训练迭代次数\n",
    "optimizer_type = 'adam' # 优化器, 可自行使用其他优化器，如SGD, RMSprop,...\n",
    "num_workers = 4 # 数据加载处理器个数\n",
    "init_lr = 0.5 # 初始学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50397c7b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:48.612712Z",
     "iopub.status.busy": "2023-10-16T01:24:48.612221Z",
     "iopub.status.idle": "2023-10-16T01:24:48.617178Z",
     "shell.execute_reply": "2023-10-16T01:24:48.617613Z"
    },
    "papermill": {
     "duration": 0.013787,
     "end_time": "2023-10-16T01:24:48.617752",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.603965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nums: 101, train: 80, val: 21\n"
     ]
    }
   ],
   "source": [
    "# 训练/验证数据集划分\n",
    "filelists = os.listdir(images_file)\n",
    "train_filelists, val_filelists = train_test_split(filelists, test_size = val_ratio,random_state = 42)\n",
    "print(\"Total Nums: {}, train: {}, val: {}\".format(len(filelists), len(train_filelists), len(val_filelists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be20e03c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:48.637724Z",
     "iopub.status.busy": "2023-10-16T01:24:48.635154Z",
     "iopub.status.idle": "2023-10-16T01:24:48.640237Z",
     "shell.execute_reply": "2023-10-16T01:24:48.639759Z"
    },
    "papermill": {
     "duration": 0.017819,
     "end_time": "2023-10-16T01:24:48.640354",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.622535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 从数据文件夹中加载眼底图像，提取相应的金标准，生成训练样本\n",
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, image_file, gt_path=None, filelists=None,  mode='train'):\n",
    "        super(OCTDataset, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.image_path = image_file\n",
    "        image_idxs = os.listdir(self.image_path) # 0001.png,\n",
    "        self.gt_path = gt_path\n",
    "        self.file_list = [image_idxs[i] for i in range(len(image_idxs))]\n",
    "        if filelists is not None:\n",
    "            self.file_list = [item for item in self.file_list if item in filelists]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_index = self.file_list[idx]\n",
    "        img_path = os.path.join(self.image_path, real_index)\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        h,w = img.shape\n",
    "        if self.mode == 'train':\n",
    "            gt_tmp_path = os.path.join(self.gt_path, real_index)\n",
    "            gt_img = cv2.imread(gt_tmp_path, 0)\n",
    "\n",
    "            ### 像素值为0的是RNFL(类别 0)，像素值为80的是GCIPL(类别 1)，像素值为160的是脉络膜(类别 2)，像素值为255的是其他（类别3）。\n",
    "\n",
    "            gt_img[gt_img == 80] = 1\n",
    "            gt_img[gt_img == 160] = 2\n",
    "            gt_img[gt_img == 255] = 3\n",
    "            gt_img = cv2.resize(gt_img,(image_size, image_size))\n",
    "            gt_img = gt_img[:,:,1]\n",
    "            # print('gt shape', gt_img.shape)\n",
    "\n",
    "        img_re = cv2.resize(img,(image_size, image_size))\n",
    "        img = img_re.reshape(1, image_size, image_size) # H, W, C -> C, H, W\n",
    "        # print(img.shape)\n",
    "        # img = img_re.astype(np.float32)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            ### 在测试过程中，加载数据返回眼底图像，数据名称，原始图像的高度和宽度\n",
    "            return img, real_index, h, w\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            ###在训练过程中，加载数据返回眼底图像及其相应的金标准\n",
    "            return img, gt_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c5901",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.004377,
     "end_time": "2023-10-16T01:24:48.649533",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.645156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**网络模型**  \n",
    "\n",
    "本基线使用模型为UNet。U-NET是一种U形网络结构，可以分为两个大阶段。首先编码器对图像进行采样，得到高级语义特征图，然后解码器对图像进行采样，将特征图恢复到原始图像的分辨率。UNet详情可参阅https://www.paddlepaddle.org.cn/documentation/docs/zh/tutorial/cv_case/image_segmentation/image_segmentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2cec54",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:48.669078Z",
     "iopub.status.busy": "2023-10-16T01:24:48.668193Z",
     "iopub.status.idle": "2023-10-16T01:24:48.691694Z",
     "shell.execute_reply": "2023-10-16T01:24:48.692172Z"
    },
    "papermill": {
     "duration": 0.035499,
     "end_time": "2023-10-16T01:24:48.692318",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.656819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeparableConv2D(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=0,\n",
    "                 dilation=1,\n",
    "                 groups=None,\n",
    "                 weight_attr=None,\n",
    "                 bias_attr=None,\n",
    "                 data_format=\"NCHW\"):\n",
    "        super(SeparableConv2D, self).__init__()\n",
    "\n",
    "        self._padding = padding\n",
    "        self._stride = stride\n",
    "        self._dilation = dilation\n",
    "        self._in_channels = in_channels\n",
    "        self._data_format = data_format\n",
    "\n",
    "        # 第一次卷积参数，没有偏置参数\n",
    "        filter_shape = [in_channels, 1] + self.convert_to_list(kernel_size, 2, 'kernel_size')\n",
    "        self.weight_conv = self.create_parameter(shape=filter_shape, attr=weight_attr)\n",
    "\n",
    "        # 第二次卷积参数\n",
    "        filter_shape = [out_channels, in_channels] + self.convert_to_list(1, 2, 'kernel_size')\n",
    "        self.weight_pointwise = self.create_parameter(shape=filter_shape, attr=weight_attr)\n",
    "        self.bias_pointwise = self.create_parameter(shape=[out_channels],\n",
    "                                                    attr=bias_attr,\n",
    "                                                    is_bias=True)\n",
    "\n",
    "    def convert_to_list(self, value, n, name, dtype=int):\n",
    "        if isinstance(value, dtype):\n",
    "            return [value, ] * n\n",
    "        else:\n",
    "            try:\n",
    "                value_list = list(value)\n",
    "            except TypeError:\n",
    "                raise ValueError(\"The \" + name +\n",
    "                                \"'s type must be list or tuple. Received: \" + str(\n",
    "                                    value))\n",
    "            if len(value_list) != n:\n",
    "                raise ValueError(\"The \" + name + \"'s length must be \" + str(n) +\n",
    "                                \". Received: \" + str(value))\n",
    "            for single_value in value_list:\n",
    "                try:\n",
    "                    dtype(single_value)\n",
    "                except (ValueError, TypeError):\n",
    "                    raise ValueError(\n",
    "                        \"The \" + name + \"'s type must be a list or tuple of \" + str(\n",
    "                            n) + \" \" + str(dtype) + \" . Received: \" + str(\n",
    "                                value) + \" \"\n",
    "                        \"including element \" + str(single_value) + \" of type\" + \" \"\n",
    "                        + str(type(single_value)))\n",
    "            return value_list\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        conv_out = F.conv2d(inputs,\n",
    "                            self.weight_conv,\n",
    "                            padding=self._padding,\n",
    "                            stride=self._stride,\n",
    "                            dilation=self._dilation,\n",
    "                            groups=self._in_channels,\n",
    "                            data_format=self._data_format)\n",
    "\n",
    "        out = F.conv2d(conv_out,\n",
    "                       self.weight_pointwise,\n",
    "                       bias=self.bias_pointwise,\n",
    "                       padding=0,\n",
    "                       stride=1,\n",
    "                       dilation=1,\n",
    "                       groups=1,\n",
    "                       data_format=self._data_format)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Layer):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.relus = nn.LayerList(\n",
    "            [nn.ReLU() for i in range(2)])\n",
    "        self.separable_conv_01 = SeparableConv2D(in_channels,\n",
    "                                                 out_channels,\n",
    "                                                 kernel_size=3,\n",
    "                                                 padding='same')\n",
    "        self.bns = nn.LayerList(\n",
    "            [nn.BatchNorm2D(out_channels) for i in range(2)])\n",
    "\n",
    "        self.separable_conv_02 = SeparableConv2D(out_channels,\n",
    "                                                 out_channels,\n",
    "                                                 kernel_size=3,\n",
    "                                                 padding='same')\n",
    "        self.pool = nn.MaxPool2D(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual_conv = nn.Conv2D(in_channels,\n",
    "                                        out_channels,\n",
    "                                        kernel_size=1,\n",
    "                                        stride=2,\n",
    "                                        padding='same')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        previous_block_activation = inputs\n",
    "\n",
    "        y = self.relus[0](inputs)\n",
    "        y = self.separable_conv_01(y)\n",
    "        y = self.bns[0](y)\n",
    "        y = self.relus[1](y)\n",
    "        y = self.separable_conv_02(y)\n",
    "        y = self.bns[1](y)\n",
    "        y = self.pool(y)\n",
    "\n",
    "        residual = self.residual_conv(previous_block_activation)\n",
    "        y = paddle.add(y, residual)\n",
    "\n",
    "        return y\n",
    "\n",
    "class Decoder(nn.Layer):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.relus = nn.LayerList(\n",
    "            [nn.ReLU() for i in range(2)])\n",
    "        self.conv_transpose_01 = nn.Conv2DTranspose(in_channels,\n",
    "                                                           out_channels,\n",
    "                                                           kernel_size=3,\n",
    "                                                           padding=1)\n",
    "        self.conv_transpose_02 = nn.Conv2DTranspose(out_channels,\n",
    "                                                           out_channels,\n",
    "                                                           kernel_size=3,\n",
    "                                                           padding=1)\n",
    "        self.bns = nn.LayerList(\n",
    "            [nn.BatchNorm2D(out_channels) for i in range(2)]\n",
    "        )\n",
    "        self.upsamples = nn.LayerList(\n",
    "            [nn.Upsample(scale_factor=2.0) for i in range(2)]\n",
    "        )\n",
    "        self.residual_conv = nn.Conv2D(in_channels,\n",
    "                                        out_channels,\n",
    "                                        kernel_size=1,\n",
    "                                        padding='same')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        previous_block_activation = inputs\n",
    "\n",
    "        y = self.relus[0](inputs)\n",
    "        y = self.conv_transpose_01(y)\n",
    "        y = self.bns[0](y)\n",
    "        y = self.relus[1](y)\n",
    "        y = self.conv_transpose_02(y)\n",
    "        y = self.bns[1](y)\n",
    "        y = self.upsamples[0](y)\n",
    "\n",
    "        residual = self.upsamples[1](previous_block_activation)\n",
    "        residual = self.residual_conv(residual)\n",
    "\n",
    "        y = paddle.add(y, residual)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d4765b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:48.710616Z",
     "iopub.status.busy": "2023-10-16T01:24:48.710114Z",
     "iopub.status.idle": "2023-10-16T01:24:48.712195Z",
     "shell.execute_reply": "2023-10-16T01:24:48.712557Z"
    },
    "papermill": {
     "duration": 0.015544,
     "end_time": "2023-10-16T01:24:48.712703",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.697159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OCT_Layer_UNet(nn.Layer):\n",
    "    def __init__(self, num_classes):\n",
    "        super(OCT_Layer_UNet, self).__init__()\n",
    "\n",
    "        self.conv_1 = nn.Conv2D(3, 32,\n",
    "                                kernel_size=3,\n",
    "                                stride=2,\n",
    "                                padding='same')\n",
    "        self.bn = nn.BatchNorm2D(32)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        in_channels = 32\n",
    "        self.encoders = []\n",
    "        self.encoder_list = [64, 128, 256]\n",
    "        self.decoder_list = [256, 128, 64, 32]\n",
    "\n",
    "        # 根据下采样个数和配置循环定义子Layer，避免重复写一样的程序\n",
    "        for out_channels in self.encoder_list:\n",
    "            block = self.add_sublayer('encoder_{}'.format(out_channels),\n",
    "                                      Encoder(in_channels, out_channels))\n",
    "            self.encoders.append(block)\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.decoders = []\n",
    "\n",
    "        # 根据上采样个数和配置循环定义子Layer，避免重复写一样的程序\n",
    "        for out_channels in self.decoder_list:\n",
    "            block = self.add_sublayer('decoder_{}'.format(out_channels),\n",
    "                                      Decoder(in_channels, out_channels))\n",
    "            self.decoders.append(block)\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.output_conv = nn.Conv2D(in_channels,\n",
    "                                            num_classes,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='same')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self.conv_1(inputs)\n",
    "        y = self.bn(y)\n",
    "        y = self.relu(y)\n",
    "\n",
    "        for encoder in self.encoders:\n",
    "            y = encoder(y)\n",
    "\n",
    "        for decoder in self.decoders:\n",
    "            y = decoder(y)\n",
    "\n",
    "        y = self.output_conv(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e723fef",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:48.730864Z",
     "iopub.status.busy": "2023-10-16T01:24:48.730349Z",
     "iopub.status.idle": "2023-10-16T01:24:48.732785Z",
     "shell.execute_reply": "2023-10-16T01:24:48.732387Z"
    },
    "papermill": {
     "duration": 0.015245,
     "end_time": "2023-10-16T01:24:48.732888",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.717643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Layer):\n",
    "    \"\"\"\n",
    "    Implements the dice loss function.\n",
    "    Args:\n",
    "        ignore_index (int64): Specifies a target value that is ignored\n",
    "            and does not contribute to the input gradient. Default ``255``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ignore_index=2):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        if len(labels.shape) != len(logits.shape):\n",
    "            labels = paddle.unsqueeze(labels, 1)\n",
    "        num_classes = logits.shape[1]\n",
    "        mask = (labels != self.ignore_index)\n",
    "        logits = logits * mask\n",
    "        labels = paddle.cast(labels, dtype='int32')\n",
    "        single_label_lists = []\n",
    "        for c in range(num_classes):\n",
    "            single_label = paddle.cast((labels == c), dtype='int32')\n",
    "            single_label = paddle.squeeze(single_label, axis=1)\n",
    "            single_label_lists.append(single_label)\n",
    "        labels_one_hot = paddle.stack(tuple(single_label_lists), axis=1)\n",
    "        logits = F.softmax(logits, axis=1)\n",
    "        labels_one_hot = paddle.cast(labels_one_hot, dtype='float32')\n",
    "        dims = (0,) + tuple(range(2, labels.ndimension()))\n",
    "        intersection = paddle.sum(logits * labels_one_hot, dims)\n",
    "        cardinality = paddle.sum(logits + labels_one_hot, dims)\n",
    "        dice_loss = (2. * intersection / (cardinality + self.eps)).mean()\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "675d4dcf",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:48.751280Z",
     "iopub.status.busy": "2023-10-16T01:24:48.750483Z",
     "iopub.status.idle": "2023-10-16T01:24:48.753041Z",
     "shell.execute_reply": "2023-10-16T01:24:48.753599Z"
    },
    "papermill": {
     "duration": 0.016282,
     "end_time": "2023-10-16T01:24:48.753775",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.737493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 训练函数\n",
    "\n",
    "def train(model, iters, train_dataloader, val_dataloader, optimizer, criterion, metric, log_interval, evl_interval):\n",
    "    iter = 0\n",
    "    model.train()\n",
    "    avg_loss_list = []\n",
    "    avg_dice_list = []\n",
    "    best_dice = 0.\n",
    "    while iter < iters:\n",
    "        for data in train_dataloader:\n",
    "            iter += 1\n",
    "            if iter > iters:\n",
    "                break\n",
    "            img = (data[0]/255.).astype(\"float32\")\n",
    "            gt_label = (data[1]).astype(\"int64\")\n",
    "            # print('label shape: ', gt_label.shape)\n",
    "            logits = model(img)\n",
    "            # print('logits shape: ', logits.shape)\n",
    "            loss = criterion(logits, gt_label)\n",
    "            # print('loss: ',loss)\n",
    "            dice = metric(logits, gt_label)\n",
    "            # print('dice: ', dice)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.clear_gradients()\n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "            avg_dice_list.append(dice.numpy()[0])\n",
    "\n",
    "            if iter % log_interval == 0:\n",
    "                avg_loss = np.array(avg_loss_list).mean()\n",
    "                avg_dice = np.array(avg_dice_list).mean()\n",
    "                avg_loss_list = []\n",
    "                avg_dice_list = []\n",
    "                print(\"[TRAIN] iter={}/{} avg_loss={:.4f} avg_dice={:.4f}\".format(iter, iters, avg_loss, avg_dice))\n",
    "\n",
    "            if iter % evl_interval == 0:\n",
    "                avg_loss, avg_dice = val(model, val_dataloader)\n",
    "                print(\"[EVAL] iter={}/{} avg_loss={:.4f} dice={:.4f}\".format(iter, iters, avg_loss, avg_dice))\n",
    "                if avg_dice >= best_dice:\n",
    "                    best_dice = avg_dice\n",
    "                    paddle.save(model.state_dict(),\n",
    "                                os.path.join(\"work/task_models/best_model_{:.4f}\".format(best_dice), 'model.pdparams'))\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab7d2a6",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:48.775092Z",
     "iopub.status.busy": "2023-10-16T01:24:48.774491Z",
     "iopub.status.idle": "2023-10-16T01:24:48.777254Z",
     "shell.execute_reply": "2023-10-16T01:24:48.777642Z"
    },
    "papermill": {
     "duration": 0.015547,
     "end_time": "2023-10-16T01:24:48.777804",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.762257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 验证函数\n",
    "\n",
    "def val(model, val_dataloader):\n",
    "    model.eval()\n",
    "    avg_loss_list = []\n",
    "    avg_dice_list = []\n",
    "    with paddle.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            img = (data[0] / 255.).astype(\"float32\")\n",
    "            gt_label = (data[1]).astype(\"int64\")\n",
    "\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, gt_label)\n",
    "            dice = metric (pred, gt_label)\n",
    "\n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "            avg_dice_list.append(dice.numpy()[0])\n",
    "\n",
    "    avg_loss = np.array(avg_loss_list).mean()\n",
    "    avg_dice = np.array(avg_dice_list).mean()\n",
    "\n",
    "    return avg_loss, avg_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e81ffed4",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:24:48.795429Z",
     "iopub.status.busy": "2023-10-16T01:24:48.794881Z",
     "iopub.status.idle": "2023-10-16T01:31:36.183712Z",
     "shell.execute_reply": "2023-10-16T01:31:36.184176Z"
    },
    "papermill": {
     "duration": 407.401245,
     "end_time": "2023-10-16T01:31:36.184332",
     "exception": false,
     "start_time": "2023-10-16T01:24:48.783087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syl20\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\paddle\\io\\reader.py:433: UserWarning: DataLoader with multi-process mode is not supported on MacOs and Windows currently. Please use signle-process mode with num_workers = 0 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 训练阶段\n",
    "# 生成训练集和验证集\n",
    "train_dataset = OCTDataset(image_file = images_file,\n",
    "                        gt_path = gt_file,\n",
    "                        filelists=train_filelists)\n",
    "\n",
    "val_dataset = OCTDataset(image_file = images_file,\n",
    "                        gt_path = gt_file,\n",
    "                        filelists=val_filelists)\n",
    "\n",
    "# 加载数据\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False),\n",
    "    num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "val_loader = paddle.io.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(val_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False),\n",
    "    num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "model = OCT_Layer_UNet(num_classes=4)\n",
    "\n",
    "if optimizer_type == \"adam\":\n",
    "    optimizer = paddle.optimizer.Adam(init_lr, parameters=model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(axis=1)\n",
    "metric = DiceLoss()\n",
    "\n",
    "# 开始训练\n",
    "# train(model, iters, train_loader, val_loader, optimizer, criterion, metric, log_interval=1, evl_interval=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba6b355",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-16T01:31:36.232292Z",
     "iopub.status.busy": "2023-10-16T01:31:36.231755Z",
     "iopub.status.idle": "2023-10-16T01:31:36.320264Z",
     "shell.execute_reply": "2023-10-16T01:31:36.320734Z"
    },
    "papermill": {
     "duration": 0.117324,
     "end_time": "2023-10-16T01:31:36.320869",
     "exception": false,
     "start_time": "2023-10-16T01:31:36.203545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "(InvalidArgument) The number of input's channels should be equal to filter's channels * groups for Op(Conv). But received: the input's channels is 1, the input's shape is [1, 1, 256, 256]; the filter's channels is 3, the filter's shape is [32, 3, 3, 3]; the groups is 1, the data_format is NCHW. The error may come from wrong data_format setting.\n  [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:1 != filter_dims[1] * groups:3.] (at ..\\paddle\\phi\\infermeta\\binary.cc:534)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\DIP\\DIP-class\\exp01_test\\6889811.ipynb 单元格 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DIP/DIP-class/exp01_test/6889811.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m img \u001b[39m=\u001b[39m img[np\u001b[39m.\u001b[39mnewaxis, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DIP/DIP-class/exp01_test/6889811.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m img \u001b[39m=\u001b[39m paddle\u001b[39m.\u001b[39mto_tensor((img \u001b[39m/\u001b[39m \u001b[39m255.\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DIP/DIP-class/exp01_test/6889811.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m logits \u001b[39m=\u001b[39m model(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DIP/DIP-class/exp01_test/6889811.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m pred_img \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DIP/DIP-class/exp01_test/6889811.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m pred_gray \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(pred_img, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\syl20\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:1254\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1246\u001b[0m     (\u001b[39mnot\u001b[39;00m in_declarative_mode())\n\u001b[0;32m   1247\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m in_profiler_mode())\n\u001b[0;32m   1252\u001b[0m ):\n\u001b[0;32m   1253\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_once(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1255\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dygraph_call_func(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32md:\\DIP\\DIP-class\\exp01_test\\6889811.ipynb 单元格 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DIP/DIP-class/exp01_test/6889811.ipynb#X21sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DIP/DIP-class/exp01_test/6889811.ipynb#X21sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_1(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DIP/DIP-class/exp01_test/6889811.ipynb#X21sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn(y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DIP/DIP-class/exp01_test/6889811.ipynb#X21sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(y)\n",
      "File \u001b[1;32mc:\\Users\\syl20\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:1254\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1246\u001b[0m     (\u001b[39mnot\u001b[39;00m in_declarative_mode())\n\u001b[0;32m   1247\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m in_profiler_mode())\n\u001b[0;32m   1252\u001b[0m ):\n\u001b[0;32m   1253\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_once(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1255\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dygraph_call_func(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\syl20\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\paddle\\nn\\layer\\conv.py:710\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_padding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    703\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(\n\u001b[0;32m    704\u001b[0m         x,\n\u001b[0;32m    705\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice,\n\u001b[0;32m    706\u001b[0m         mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_padding_mode,\n\u001b[0;32m    707\u001b[0m         data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_format,\n\u001b[0;32m    708\u001b[0m     )\n\u001b[1;32m--> 710\u001b[0m out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mconv\u001b[39m.\u001b[39;49m_conv_nd(\n\u001b[0;32m    711\u001b[0m     x,\n\u001b[0;32m    712\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    713\u001b[0m     bias\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    714\u001b[0m     stride\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stride,\n\u001b[0;32m    715\u001b[0m     padding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_updated_padding,\n\u001b[0;32m    716\u001b[0m     padding_algorithm\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_padding_algorithm,\n\u001b[0;32m    717\u001b[0m     dilation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dilation,\n\u001b[0;32m    718\u001b[0m     groups\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_groups,\n\u001b[0;32m    719\u001b[0m     data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_format,\n\u001b[0;32m    720\u001b[0m     channel_dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_channel_dim,\n\u001b[0;32m    721\u001b[0m     op_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op_type,\n\u001b[0;32m    722\u001b[0m     use_cudnn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_use_cudnn,\n\u001b[0;32m    723\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\syl20\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\paddle\\nn\\functional\\conv.py:133\u001b[0m, in \u001b[0;36m_conv_nd\u001b[1;34m(x, weight, bias, stride, padding, padding_algorithm, dilation, groups, data_format, channel_dim, op_type, use_cudnn, use_mkldnn, name)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_conv_nd\u001b[39m(\n\u001b[0;32m    115\u001b[0m     x,\n\u001b[0;32m    116\u001b[0m     weight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m     \u001b[39m# Due to the poor performance of NHWC, we transpose the input to NCHW.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[39mif\u001b[39;00m in_dynamic_mode() \u001b[39mand\u001b[39;00m op_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconv2d\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 133\u001b[0m         pre_bias \u001b[39m=\u001b[39m _C_ops\u001b[39m.\u001b[39;49mconv2d(\n\u001b[0;32m    134\u001b[0m             x,\n\u001b[0;32m    135\u001b[0m             weight,\n\u001b[0;32m    136\u001b[0m             stride,\n\u001b[0;32m    137\u001b[0m             padding,\n\u001b[0;32m    138\u001b[0m             padding_algorithm,\n\u001b[0;32m    139\u001b[0m             dilation,\n\u001b[0;32m    140\u001b[0m             groups,\n\u001b[0;32m    141\u001b[0m             data_format,\n\u001b[0;32m    142\u001b[0m         )\n\u001b[0;32m    143\u001b[0m         \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m             new_shape \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: (InvalidArgument) The number of input's channels should be equal to filter's channels * groups for Op(Conv). But received: the input's channels is 1, the input's shape is [1, 1, 256, 256]; the filter's channels is 3, the filter's shape is [32, 3, 3, 3]; the groups is 1, the data_format is NCHW. The error may come from wrong data_format setting.\n  [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:1 != filter_dims[1] * groups:3.] (at ..\\paddle\\phi\\infermeta\\binary.cc:534)\n"
     ]
    }
   ],
   "source": [
    "# 预测阶段\n",
    "# 加载模型参数\n",
    "test_file = 'work/Validation/Image'  # 测试图像路径\n",
    "best_model_path = \"work/task_models/best_model_0.0084/model.pdparams\"\n",
    "model = OCT_Layer_UNet(num_classes = 4)\n",
    "para_state_dict = paddle.load(best_model_path)\n",
    "model.set_state_dict(para_state_dict)\n",
    "model.eval()\n",
    "\n",
    "# 生成测试集\n",
    "\n",
    "test_dataset = OCTDataset(image_file = test_file,\n",
    "                            mode='test')\n",
    "# 一张一张分割测试集中的图像\n",
    "# 分割结果存储格式为png\n",
    "\n",
    "for img, idx, h, w in test_dataset:\n",
    "    # print(idx)\n",
    "    img = img[np.newaxis, ...]\n",
    "    img = paddle.to_tensor((img / 255.).astype(\"float32\"))\n",
    "    logits = model(img)\n",
    "    pred_img = logits.numpy().argmax(1)\n",
    "    pred_gray = np.squeeze(pred_img, axis=0)\n",
    "    pred_gray = pred_gray.astype('float32')\n",
    "    # print(pred_gray.shape)\n",
    "    pred_gray[pred_gray == 1] = 80\n",
    "    pred_gray[pred_gray == 2] = 160\n",
    "    pred_gray[pred_gray == 3] = 255\n",
    "    # print(pred_gray)\n",
    "    pred_ = cv2.resize(pred_gray, (w, h))\n",
    "    # print(pred_.shape)\n",
    "    cv2.imwrite('work/Validation/Output_show/'+idx, pred_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042aad7",
   "metadata": {
    "collapsed": false,
    "papermill": {
     "duration": 0.019244,
     "end_time": "2023-10-16T01:31:36.359067",
     "exception": false,
     "start_time": "2023-10-16T01:31:36.339823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 414.439096,
   "end_time": "2023-10-16T01:31:38.908724",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/aistudio/6889811.ipynb",
   "output_path": "/home/aistudio/.6889811.ipynb",
   "parameters": {},
   "start_time": "2023-10-16T01:24:44.469628",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
