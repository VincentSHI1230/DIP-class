{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**GOALS挑战赛任务一基线**  \n",
    "\n",
    "赛题链接：MICCAI2022 Challenge: GOALS (Task 1)\n",
    "https://aistudio.baidu.com/aistudio/competition/detail/230/0/introduction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**比赛简介**  \n",
    "\n",
    "GOALS挑战赛是由百度在MICCAI 2022上举办的国际眼科赛事。MICCAI是由国际医学图像计算和计算机辅助干预协会 (Medical Image Computing and Computer Assisted Intervention Society) 举办的跨医学影像计算和计算机辅助介入两个领域的综合性学术会议，是该领域的顶级会议。与此同时，百度将在MICCAI 2022上组织第九届眼科医学影像分析研讨会Ophthalmic Medical Image Analysis (OMIA9)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**基线任务说明**    \n",
    "\n",
    "本基线对应GOALS比赛任务1，目的是在环扫OCT图像中分割视神经纤维层、神经节细胞丛层和脉络膜层区域。\n",
    "本基线使用了U型网络结构，并在编码和解码阶段加入了残差模块，模型结构如下图所示。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/dc2e371fe6544123a77700563b85598660d3f09f006b4d6d8696d268d5b045c0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**数据集说明**  \n",
    "\n",
    "本基线使用的数据集为GOALS比赛释放的环扫OCT图像。代码中提供的读入数据仅供基线正常运行，并非完整比赛数据集。\n",
    "各位同学可通过报名GOALS比赛获得相应数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.io import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 设置参数\n",
    "images_file = 'work/image'  # 训练图像路径\n",
    "gt_file = 'work/layer_masks/'\n",
    "image_size = 256 # 输入图像统一尺寸\n",
    "val_ratio = 0.2  # 训练/验证图像划分比例\n",
    "BATCH_SIZE = 8 # 批大小\n",
    "iters = 3000 # 训练迭代次数\n",
    "optimizer_type = 'adam' # 优化器, 可自行使用其他优化器，如SGD, RMSprop,...\n",
    "num_workers = 4 # 数据加载处理器个数\n",
    "init_lr = 1e-3 # 初始学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nums: 8, train: 6, val: 2\n"
     ]
    }
   ],
   "source": [
    "# 训练/验证数据集划分\n",
    "filelists = os.listdir(images_file)\n",
    "train_filelists, val_filelists = train_test_split(filelists, test_size = val_ratio,random_state = 42)\n",
    "print(\"Total Nums: {}, train: {}, val: {}\".format(len(filelists), len(train_filelists), len(val_filelists)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 从数据文件夹中加载眼底图像，提取相应的金标准，生成训练样本\n",
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, image_file, gt_path=None, filelists=None,  mode='train'):\n",
    "        super(OCTDataset, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.image_path = image_file\n",
    "        image_idxs = os.listdir(self.image_path) # 0001.png,\n",
    "        self.gt_path = gt_path\n",
    "        self.file_list = [image_idxs[i] for i in range(len(image_idxs))]        \n",
    "        if filelists is not None:\n",
    "            self.file_list = [item for item in self.file_list if item in filelists] \n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        real_index = self.file_list[idx]\n",
    "        img_path = os.path.join(self.image_path, real_index)\n",
    "        img = cv2.imread(img_path) \n",
    "        h,w,c = img.shape      \n",
    "        if self.mode == 'train':\n",
    "            gt_tmp_path = os.path.join(self.gt_path, real_index)\n",
    "            gt_img = cv2.imread(gt_tmp_path)\n",
    "\n",
    "            ### 像素值为0的是RNFL(类别 0)，像素值为80的是GCIPL(类别 1)，像素值为160的是脉络膜(类别 2)，像素值为255的是其他（类别3）。\n",
    "            \n",
    "            gt_img[gt_img == 80] = 1\n",
    "            gt_img[gt_img == 160] = 2\n",
    "            gt_img[gt_img == 255] = 3\n",
    "            gt_img = cv2.resize(gt_img,(image_size, image_size))\n",
    "            gt_img = gt_img[:,:,1]\n",
    "            # print('gt shape', gt_img.shape)           \n",
    "\n",
    "        img_re = cv2.resize(img,(image_size, image_size))\n",
    "        img = img_re.transpose(2, 0, 1) # H, W, C -> C, H, W\n",
    "        # print(img.shape)\n",
    "        # img = img_re.astype(np.float32)\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            ### 在测试过程中，加载数据返回眼底图像，数据名称，原始图像的高度和宽度\n",
    "            return img, real_index, h, w\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            ###在训练过程中，加载数据返回眼底图像及其相应的金标准           \n",
    "            return img, gt_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**网络模型**  \n",
    "\n",
    "本基线使用模型为UNet。U-NET是一种U形网络结构，可以分为两个大阶段。首先编码器对图像进行采样，得到高级语义特征图，然后解码器对图像进行采样，将特征图恢复到原始图像的分辨率。UNet详情可参阅https://www.paddlepaddle.org.cn/documentation/docs/zh/tutorial/cv_case/image_segmentation/image_segmentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SeparableConv2D(nn.Layer):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 kernel_size, \n",
    "                 stride=1, \n",
    "                 padding=0, \n",
    "                 dilation=1, \n",
    "                 groups=None, \n",
    "                 weight_attr=None, \n",
    "                 bias_attr=None, \n",
    "                 data_format=\"NCHW\"):\n",
    "        super(SeparableConv2D, self).__init__()\n",
    "\n",
    "        self._padding = padding\n",
    "        self._stride = stride\n",
    "        self._dilation = dilation\n",
    "        self._in_channels = in_channels\n",
    "        self._data_format = data_format\n",
    "\n",
    "        # 第一次卷积参数，没有偏置参数\n",
    "        filter_shape = [in_channels, 1] + self.convert_to_list(kernel_size, 2, 'kernel_size')\n",
    "        self.weight_conv = self.create_parameter(shape=filter_shape, attr=weight_attr)\n",
    "\n",
    "        # 第二次卷积参数\n",
    "        filter_shape = [out_channels, in_channels] + self.convert_to_list(1, 2, 'kernel_size')\n",
    "        self.weight_pointwise = self.create_parameter(shape=filter_shape, attr=weight_attr)\n",
    "        self.bias_pointwise = self.create_parameter(shape=[out_channels], \n",
    "                                                    attr=bias_attr, \n",
    "                                                    is_bias=True)\n",
    "    \n",
    "    def convert_to_list(self, value, n, name, dtype=np.int):\n",
    "        if isinstance(value, dtype):\n",
    "            return [value, ] * n\n",
    "        else:\n",
    "            try:\n",
    "                value_list = list(value)\n",
    "            except TypeError:\n",
    "                raise ValueError(\"The \" + name +\n",
    "                                \"'s type must be list or tuple. Received: \" + str(\n",
    "                                    value))\n",
    "            if len(value_list) != n:\n",
    "                raise ValueError(\"The \" + name + \"'s length must be \" + str(n) +\n",
    "                                \". Received: \" + str(value))\n",
    "            for single_value in value_list:\n",
    "                try:\n",
    "                    dtype(single_value)\n",
    "                except (ValueError, TypeError):\n",
    "                    raise ValueError(\n",
    "                        \"The \" + name + \"'s type must be a list or tuple of \" + str(\n",
    "                            n) + \" \" + str(dtype) + \" . Received: \" + str(\n",
    "                                value) + \" \"\n",
    "                        \"including element \" + str(single_value) + \" of type\" + \" \"\n",
    "                        + str(type(single_value)))\n",
    "            return value_list\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        conv_out = F.conv2d(inputs, \n",
    "                            self.weight_conv, \n",
    "                            padding=self._padding,\n",
    "                            stride=self._stride,\n",
    "                            dilation=self._dilation,\n",
    "                            groups=self._in_channels,\n",
    "                            data_format=self._data_format)\n",
    "        \n",
    "        out = F.conv2d(conv_out,\n",
    "                       self.weight_pointwise,\n",
    "                       bias=self.bias_pointwise,\n",
    "                       padding=0,\n",
    "                       stride=1,\n",
    "                       dilation=1,\n",
    "                       groups=1,\n",
    "                       data_format=self._data_format)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Layer):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.relus = nn.LayerList(\n",
    "            [nn.ReLU() for i in range(2)])\n",
    "        self.separable_conv_01 = SeparableConv2D(in_channels, \n",
    "                                                 out_channels, \n",
    "                                                 kernel_size=3, \n",
    "                                                 padding='same')\n",
    "        self.bns = nn.LayerList(\n",
    "            [nn.BatchNorm2D(out_channels) for i in range(2)])\n",
    "        \n",
    "        self.separable_conv_02 = SeparableConv2D(out_channels, \n",
    "                                                 out_channels, \n",
    "                                                 kernel_size=3, \n",
    "                                                 padding='same')\n",
    "        self.pool = nn.MaxPool2D(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual_conv = nn.Conv2D(in_channels, \n",
    "                                        out_channels, \n",
    "                                        kernel_size=1, \n",
    "                                        stride=2, \n",
    "                                        padding='same')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        previous_block_activation = inputs\n",
    "        \n",
    "        y = self.relus[0](inputs)\n",
    "        y = self.separable_conv_01(y)\n",
    "        y = self.bns[0](y)\n",
    "        y = self.relus[1](y)\n",
    "        y = self.separable_conv_02(y)\n",
    "        y = self.bns[1](y)\n",
    "        y = self.pool(y)\n",
    "        \n",
    "        residual = self.residual_conv(previous_block_activation)\n",
    "        y = paddle.add(y, residual)\n",
    "\n",
    "        return y\n",
    "\n",
    "class Decoder(nn.Layer):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.relus = nn.LayerList(\n",
    "            [nn.ReLU() for i in range(2)])\n",
    "        self.conv_transpose_01 = nn.Conv2DTranspose(in_channels, \n",
    "                                                           out_channels, \n",
    "                                                           kernel_size=3, \n",
    "                                                           padding=1)\n",
    "        self.conv_transpose_02 = nn.Conv2DTranspose(out_channels, \n",
    "                                                           out_channels, \n",
    "                                                           kernel_size=3, \n",
    "                                                           padding=1)\n",
    "        self.bns = nn.LayerList(\n",
    "            [nn.BatchNorm2D(out_channels) for i in range(2)]\n",
    "        )\n",
    "        self.upsamples = nn.LayerList(\n",
    "            [nn.Upsample(scale_factor=2.0) for i in range(2)]\n",
    "        )\n",
    "        self.residual_conv = nn.Conv2D(in_channels, \n",
    "                                        out_channels, \n",
    "                                        kernel_size=1, \n",
    "                                        padding='same')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        previous_block_activation = inputs\n",
    "\n",
    "        y = self.relus[0](inputs)\n",
    "        y = self.conv_transpose_01(y)\n",
    "        y = self.bns[0](y)\n",
    "        y = self.relus[1](y)\n",
    "        y = self.conv_transpose_02(y)\n",
    "        y = self.bns[1](y)\n",
    "        y = self.upsamples[0](y)\n",
    "        \n",
    "        residual = self.upsamples[1](previous_block_activation)\n",
    "        residual = self.residual_conv(residual)\n",
    "        \n",
    "        y = paddle.add(y, residual)\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OCT_Layer_UNet(nn.Layer):\n",
    "    def __init__(self, num_classes):\n",
    "        super(OCT_Layer_UNet, self).__init__()\n",
    "\n",
    "        self.conv_1 = nn.Conv2D(3, 32, \n",
    "                                kernel_size=3,\n",
    "                                stride=2,\n",
    "                                padding='same')\n",
    "        self.bn = nn.BatchNorm2D(32)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        in_channels = 32\n",
    "        self.encoders = []\n",
    "        self.encoder_list = [64, 128, 256]\n",
    "        self.decoder_list = [256, 128, 64, 32]\n",
    "\n",
    "        # 根据下采样个数和配置循环定义子Layer，避免重复写一样的程序\n",
    "        for out_channels in self.encoder_list:\n",
    "            block = self.add_sublayer('encoder_{}'.format(out_channels),\n",
    "                                      Encoder(in_channels, out_channels))\n",
    "            self.encoders.append(block)\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.decoders = []\n",
    "\n",
    "        # 根据上采样个数和配置循环定义子Layer，避免重复写一样的程序\n",
    "        for out_channels in self.decoder_list:\n",
    "            block = self.add_sublayer('decoder_{}'.format(out_channels), \n",
    "                                      Decoder(in_channels, out_channels))\n",
    "            self.decoders.append(block)\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.output_conv = nn.Conv2D(in_channels, \n",
    "                                            num_classes, \n",
    "                                            kernel_size=3, \n",
    "                                            padding='same')\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        y = self.conv_1(inputs)\n",
    "        y = self.bn(y)\n",
    "        y = self.relu(y)\n",
    "        \n",
    "        for encoder in self.encoders:\n",
    "            y = encoder(y)\n",
    "\n",
    "        for decoder in self.decoders:\n",
    "            y = decoder(y)\n",
    "        \n",
    "        y = self.output_conv(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Layer):\n",
    "    \"\"\"\n",
    "    Implements the dice loss function.\n",
    "    Args:\n",
    "        ignore_index (int64): Specifies a target value that is ignored\n",
    "            and does not contribute to the input gradient. Default ``255``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ignore_index=2):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        if len(labels.shape) != len(logits.shape):\n",
    "            labels = paddle.unsqueeze(labels, 1)\n",
    "        num_classes = logits.shape[1]\n",
    "        mask = (labels != self.ignore_index)\n",
    "        logits = logits * mask\n",
    "        labels = paddle.cast(labels, dtype='int32')\n",
    "        single_label_lists = []\n",
    "        for c in range(num_classes):\n",
    "            single_label = paddle.cast((labels == c), dtype='int32')\n",
    "            single_label = paddle.squeeze(single_label, axis=1)\n",
    "            single_label_lists.append(single_label)\n",
    "        labels_one_hot = paddle.stack(tuple(single_label_lists), axis=1)\n",
    "        logits = F.softmax(logits, axis=1)\n",
    "        labels_one_hot = paddle.cast(labels_one_hot, dtype='float32')\n",
    "        dims = (0,) + tuple(range(2, labels.ndimension()))\n",
    "        intersection = paddle.sum(logits * labels_one_hot, dims)\n",
    "        cardinality = paddle.sum(logits + labels_one_hot, dims)\n",
    "        dice_loss = (2. * intersection / (cardinality + self.eps)).mean()\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 训练函数\n",
    "\n",
    "def train(model, iters, train_dataloader, val_dataloader, optimizer, criterion, metric, log_interval, evl_interval):\n",
    "    iter = 0\n",
    "    model.train()\n",
    "    avg_loss_list = []\n",
    "    avg_dice_list = []\n",
    "    best_dice = 0.\n",
    "    while iter < iters:\n",
    "        for data in train_dataloader:\n",
    "            iter += 1\n",
    "            if iter > iters:\n",
    "                break\n",
    "            img = (data[0]/255.).astype(\"float32\")\n",
    "            gt_label = (data[1]).astype(\"int64\")\n",
    "            # print('label shape: ', gt_label.shape)\n",
    "            logits = model(img)\n",
    "            # print('logits shape: ', logits.shape)\n",
    "            loss = criterion(logits, gt_label)\n",
    "            # print('loss: ',loss)\n",
    "            dice = metric(logits, gt_label) \n",
    "            # print('dice: ', dice)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.clear_gradients()\n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "            avg_dice_list.append(dice.numpy()[0]) \n",
    "\n",
    "            if iter % log_interval == 0:\n",
    "                avg_loss = np.array(avg_loss_list).mean()\n",
    "                avg_dice = np.array(avg_dice_list).mean()\n",
    "                avg_loss_list = []\n",
    "                avg_dice_list = []\n",
    "                print(\"[TRAIN] iter={}/{} avg_loss={:.4f} avg_dice={:.4f}\".format(iter, iters, avg_loss, avg_dice))\n",
    "\n",
    "            if iter % evl_interval == 0:\n",
    "                avg_loss, avg_dice = val(model, val_dataloader)\n",
    "                print(\"[EVAL] iter={}/{} avg_loss={:.4f} dice={:.4f}\".format(iter, iters, avg_loss, avg_dice))\n",
    "                if avg_dice >= best_dice:\n",
    "                    best_dice = avg_dice\n",
    "                    paddle.save(model.state_dict(),\n",
    "                                os.path.join(\"/xx/task2_models/best_model_{:.4f}\".format(best_dice), 'model.pdparams'))\n",
    "                model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 验证函数\n",
    "\n",
    "def val(model, val_dataloader):\n",
    "    model.eval()\n",
    "    avg_loss_list = []\n",
    "    avg_dice_list = []\n",
    "    with paddle.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            img = (data[0] / 255.).astype(\"float32\")\n",
    "            gt_label = (data[1]).astype(\"int64\")\n",
    "\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, gt_label)\n",
    "            dice = metric (pred, gt_label)  \n",
    "\n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "            avg_dice_list.append(dice.numpy()[0])\n",
    "\n",
    "    avg_loss = np.array(avg_loss_list).mean()\n",
    "    avg_dice = np.array(avg_dice_list).mean()\n",
    "\n",
    "    return avg_loss, avg_dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 22:22:58.693598   133 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.0, Runtime API Version: 11.2\n",
      "W1015 22:22:58.697840   133 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:278: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.bool, the right dtype will convert to paddle.float32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] iter=10/3000 avg_loss=5.3078 avg_dice=0.2704\n",
      "[TRAIN] iter=20/3000 avg_loss=1.9432 avg_dice=0.3339\n",
      "[TRAIN] iter=30/3000 avg_loss=0.6867 avg_dice=0.3553\n",
      "[TRAIN] iter=40/3000 avg_loss=0.4051 avg_dice=0.3455\n",
      "[TRAIN] iter=50/3000 avg_loss=0.3216 avg_dice=0.3860\n",
      "[EVAL] iter=50/3000 avg_loss=0.5650 dice=0.3097\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/xx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_133/3012642335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# 开始训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevl_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_133/871496000.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iters, train_dataloader, val_dataloader, optimizer, criterion, metric, log_interval, evl_interval)\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mbest_dice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_dice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     paddle.save(model.state_dict(),\n\u001b[0;32m---> 44\u001b[0;31m                                 os.path.join(\"/xx/task2_models/best_model_{:.4f}\".format(best_dice), 'model.pdparams'))\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/framework/io.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, path, protocol, **configs)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_memory_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/xx'"
     ]
    }
   ],
   "source": [
    "# 训练阶段\n",
    "# 生成训练集和验证集\n",
    "train_dataset = OCTDataset(image_file = images_file, \n",
    "                        gt_path = gt_file,\n",
    "                        filelists=train_filelists)\n",
    "\n",
    "val_dataset = OCTDataset(image_file = images_file, \n",
    "                        gt_path = gt_file,\n",
    "                        filelists=val_filelists)\n",
    "\n",
    "# 加载数据\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False),\n",
    "    num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "val_loader = paddle.io.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(val_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False),\n",
    "    num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "model = OCT_Layer_UNet(num_classes=4)\n",
    "\n",
    "if optimizer_type == \"adam\":\n",
    "    optimizer = paddle.optimizer.Adam(init_lr, parameters=model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(axis=1)\n",
    "metric = DiceLoss()\n",
    "\n",
    "# 开始训练\n",
    "train(model, iters, train_loader, val_loader, optimizer, criterion, metric, log_interval=10, evl_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 预测阶段\n",
    "# 加载模型参数\n",
    "test_file = 'work/image'  # 测试图像路径\n",
    "best_model_path = \"work/model.pdparams\"\n",
    "model = OCT_Layer_UNet(num_classes = 4)\n",
    "para_state_dict = paddle.load(best_model_path)\n",
    "model.set_state_dict(para_state_dict)\n",
    "model.eval()\n",
    "\n",
    "# 生成测试集\n",
    "\n",
    "test_dataset = OCTDataset(image_file = test_file, \n",
    "                            mode='test')\n",
    "# 一张一张分割测试集中的图像\n",
    "# 分割结果存储格式为png\n",
    "\n",
    "for img, idx, h, w in test_dataset:\n",
    "    # print(idx)\n",
    "    img = img[np.newaxis, ...]\n",
    "    img = paddle.to_tensor((img / 255.).astype(\"float32\"))\n",
    "    logits = model(img)\n",
    "    pred_img = logits.numpy().argmax(1)\n",
    "    pred_gray = np.squeeze(pred_img, axis=0)\n",
    "    pred_gray = pred_gray.astype('float32')\n",
    "    # print(pred_gray.shape)\n",
    "    pred_gray[pred_gray == 1] = 80\n",
    "    pred_gray[pred_gray == 2] = 160\n",
    "    pred_gray[pred_gray == 3] = 255\n",
    "    # print(pred_gray)\n",
    "    pred_ = cv2.resize(pred_gray, (w, h))\n",
    "    # print(pred_.shape)\n",
    "    cv2.imwrite('work/Layer_Segmentations/'+idx, pred_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
